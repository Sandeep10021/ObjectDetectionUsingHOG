{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection using HOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Table of Contents</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ 1. Importing Libraries](#section1)<br>\n",
    "[ 2. HOG Feature Extraction](#section2)<br>\n",
    "[ 3. Sample of EXtracted HOG Feature](#section3)<br>\n",
    "[ 4. Model Training](#section4)<br>\n",
    "[ 5. Testing the Model](#section5)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <a id = 'section1'> <font color='grey'>  1. Importing Libraries </font> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import pyramid_gaussian\n",
    "from skimage.io import imread\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import color\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import imutils, argparse, cv2, os, glob, joblib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <a id = 'section2'> <font color='grey'>  2. HOG Feature Extraction </font> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function for defining cells \n",
    "def cell(magnitude,orientation,orientation_start,orientation_end,cell_columns,cell_rows,\n",
    "         column_index,row_index,size_columns,size_rows,range_rows_start,range_rows_stop,\n",
    "         range_columns_start,range_columns_stop):\n",
    "    \n",
    "    total=0\n",
    "    \n",
    "    for cell_row in range(int(range_rows_start),int(range_rows_stop)):\n",
    "        cell_row_index = row_index + cell_row\n",
    "        if (cell_row_index < 0 or cell_row_index >= size_rows):\n",
    "            continue\n",
    "\n",
    "        for cell_column in range(int(range_columns_start), int(range_columns_stop)):\n",
    "            cell_column_index = column_index + cell_column\n",
    "            if (cell_column_index < 0 or cell_column_index >= size_columns\n",
    "                    or orientation[int(cell_row_index), int(cell_column_index)]\n",
    "                    >= orientation_start\n",
    "                    or orientation[int(cell_row_index), int(cell_column_index)]\n",
    "                    < orientation_end):\n",
    "                continue\n",
    "\n",
    "            total += magnitude[int(cell_row_index), int(cell_column_index)]\n",
    "\n",
    "    return total / (cell_rows * cell_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to calculate histogram \n",
    "def hog_histograms(gradient_columns,gradient_rows,\n",
    "                   cell_columns,cell_rows,\n",
    "                   size_columns,size_rows,\n",
    "                   number_of_cells_columns,number_of_cells_rows,\n",
    "                   number_of_orientations,\n",
    "                   orientation_histogram):\n",
    "\n",
    "    magnitude = np.hypot(gradient_columns,gradient_rows)\n",
    "    orientation = np.rad2deg(np.arctan2(gradient_rows, gradient_columns)) % 180\n",
    "\n",
    "\n",
    "    r_0 = cell_rows / 2\n",
    "    c_0 = cell_columns / 2\n",
    "    cc = cell_rows * number_of_cells_rows\n",
    "    cr = cell_columns * number_of_cells_columns\n",
    "    range_rows_stop = cell_rows / 2\n",
    "    range_rows_start = -range_rows_stop\n",
    "    range_columns_stop = cell_columns / 2\n",
    "    range_columns_start = -range_columns_stop\n",
    "    number_of_orientations_per_180 = 180 / number_of_orientations\n",
    "\n",
    "\n",
    "    # compute orientations integral images\n",
    "    for i in range(number_of_orientations):\n",
    "        # isolate orientations in this range\n",
    "        orientation_start = number_of_orientations_per_180 * (i + 1)\n",
    "        orientation_end = number_of_orientations_per_180 * i\n",
    "        c = c_0\n",
    "        r = r_0\n",
    "        r_i = 0\n",
    "        c_i = 0\n",
    "\n",
    "        while r < cc:\n",
    "            c_i = 0\n",
    "            c = c_0\n",
    "\n",
    "            while c < cr:\n",
    "                orientation_histogram[r_i, c_i, i] = \\\n",
    "                    cell(magnitude, orientation,\n",
    "                             orientation_start, orientation_end,\n",
    "                             cell_columns, cell_rows, c, r,\n",
    "                             size_columns, size_rows,\n",
    "                             range_rows_start, range_rows_stop,\n",
    "                             range_columns_start, range_columns_stop)\n",
    "                c_i += 1\n",
    "                c += cell_columns\n",
    "\n",
    "            r_i += 1\n",
    "            r += cell_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to normalize the blcoks\n",
    "def normalize_block(block, method, eps=1e-5):\n",
    "    if method == 'L1':\n",
    "        out = block / (np.sum(np.abs(block)) + eps)\n",
    "    elif method == 'L2':\n",
    "        out = block / np.sqrt(np.sum(block ** 2) + eps ** 2)\n",
    "    else:\n",
    "        raise ValueError('Please select a valid normalization method')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to calculate the gradient of image\n",
    "def gradient_hog(channel):\n",
    "    \n",
    "    g_row = np.empty(channel.shape, dtype=np.double)\n",
    "    g_row[0, :] = 0\n",
    "    g_row[-1, :] = 0\n",
    "    g_row[1:-1, :] = channel[2:, :] - channel[:-2, :]\n",
    "    g_col = np.empty(channel.shape, dtype=np.double)\n",
    "    g_col[:, 0] = 0\n",
    "    g_col[:, -1] = 0\n",
    "    g_col[:, 1:-1] = channel[:, 2:] - channel[:, :-2]\n",
    "\n",
    "    return g_row, g_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to extract all features of hog\n",
    "def hog_nd(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2,2),\n",
    "        block_norm='L2', visualize=False, transform_sqrt=False,\n",
    "        feature_vector=True, multichannel=None):\n",
    "\n",
    "    image = np.atleast_2d(image)\n",
    "\n",
    "    if multichannel is None:\n",
    "        multichannel = (image.ndim == 3)\n",
    "\n",
    "    ndim_spatial = image.ndim - 1 if multichannel else image.ndim\n",
    "    if ndim_spatial != 2:\n",
    "        raise ValueError('Only images with 2 spatial dimensions are '\n",
    "                         'supported. If using with color/multichannel '\n",
    "                         'images, specify `multichannel=True`.')\n",
    "\n",
    "\n",
    "    if transform_sqrt:\n",
    "        image = np.sqrt(image)\n",
    "\n",
    "\n",
    "    if image.dtype.kind == 'u':\n",
    "        # convert uint image to float\n",
    "        # to avoid problems with subtracting unsigned numbers\n",
    "        image = image.astype('float')\n",
    "\n",
    "    if multichannel:\n",
    "        g_row_by_ch = np.empty_like(image, dtype=np.double)\n",
    "        g_col_by_ch = np.empty_like(image, dtype=np.double)\n",
    "        g_magn = np.empty_like(image, dtype=np.double)\n",
    "\n",
    "        for idx_ch in range(image.shape[2]):\n",
    "            g_row_by_ch[:, :, idx_ch], g_col_by_ch[:, :, idx_ch] = \\\n",
    "                gradient_hog(image[:, :, idx_ch])\n",
    "            g_magn[:, :, idx_ch] = np.hypot(g_row_by_ch[:, :, idx_ch],\n",
    "                                            g_col_by_ch[:, :, idx_ch])\n",
    "\n",
    "        # For each pixel select the channel with the highest gradient magnitude\n",
    "        idcs_max = g_magn.argmax(axis=2)\n",
    "        rr, cc = np.meshgrid(np.arange(image.shape[0]),\n",
    "                             np.arange(image.shape[1]),\n",
    "                             indexing='ij',\n",
    "                             sparse=True)\n",
    "        g_row = g_row_by_ch[rr, cc, idcs_max]\n",
    "        g_col = g_col_by_ch[rr, cc, idcs_max]\n",
    "    else:\n",
    "        g_row, g_col = gradient_hog(image)\n",
    "\n",
    "\n",
    "    s_row, s_col = image.shape[:2]\n",
    "    c_row, c_col = pixels_per_cell\n",
    "    b_row, b_col = cells_per_block\n",
    "\n",
    "    n_cells_row = int(s_row // c_row)  # number of cells along row-axis\n",
    "    n_cells_col = int(s_col // c_col)  # number of cells along col-axis\n",
    "\n",
    "    # compute orientations integral images\n",
    "    orientation_histogram = np.zeros((n_cells_row, n_cells_col, orientations))\n",
    "\n",
    "    hog_histograms(g_col, g_row, c_col, c_row, s_col, s_row,\n",
    "                                 n_cells_col, n_cells_row,\n",
    "                                 orientations, orientation_histogram)\n",
    "\n",
    "    # now compute the histogram for each cell\n",
    "    hog_image = None\n",
    "\n",
    "    if visualize:\n",
    "        from skimage.draw import draw\n",
    "\n",
    "        radius = min(c_row, c_col) // 2 - 1\n",
    "        orientations_arr = np.arange(orientations)\n",
    "        # set dr_arr, dc_arr to correspond to midpoints of orientation bins\n",
    "        orientation_bin_midpoints = (\n",
    "            np.pi * (orientations_arr + .5) / orientations)\n",
    "        dr_arr = radius * np.sin(orientation_bin_midpoints)\n",
    "        dc_arr = radius * np.cos(orientation_bin_midpoints)\n",
    "        hog_image = np.zeros((s_row, s_col), dtype=float)\n",
    "        for r in range(n_cells_row):\n",
    "            for c in range(n_cells_col):\n",
    "                for o, dr, dc in zip(orientations_arr, dr_arr, dc_arr):\n",
    "                    centre = tuple([r * c_row + c_row // 2,\n",
    "                                    c * c_col + c_col // 2])\n",
    "                    rr, cc = draw.line(int(centre[0] - dc),\n",
    "                                       int(centre[1] + dr),\n",
    "                                       int(centre[0] + dc),\n",
    "                                       int(centre[1] - dr))\n",
    "                    hog_image[rr, cc] += orientation_histogram[r, c, o]\n",
    "\n",
    "\n",
    "    n_blocks_row = (n_cells_row - b_row) + 1\n",
    "    n_blocks_col = (n_cells_col - b_col) + 1\n",
    "    normalized_blocks = np.zeros((n_blocks_row, n_blocks_col,\n",
    "                                  b_row, b_col, orientations))\n",
    "\n",
    "    for r in range(n_blocks_row):\n",
    "        for c in range(n_blocks_col):\n",
    "            block = orientation_histogram[r:r + b_row, c:c + b_col, :]\n",
    "            normalized_blocks[r, c, :] = \\\n",
    "                normalize_block(block, method=block_norm)\n",
    "\n",
    "\n",
    "    if feature_vector:\n",
    "        normalized_blocks = normalized_blocks.ravel()\n",
    "\n",
    "    if visualize:\n",
    "        return normalized_blocks, hog_image\n",
    "    else:\n",
    "        return normalized_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <a id = 'section3'> <font color='grey'>  3. Sample of Extracted HOG Features</font> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path for sample dataset\n",
    "img = imread(r\"test/test1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = color.rgb2gray(img)\n",
    "\n",
    "fd, hog_image = hog_nd(image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                    cells_per_block=(2,2), visualize=True)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "\n",
    "ax1.axis('off')\n",
    "ax1.imshow(image, cmap=plt.cm.gray)\n",
    "ax1.set_title('Input image')\n",
    "ax1.set_adjustable('box')\n",
    "\n",
    "# Rescale histogram for better display\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 0.02))\n",
    "\n",
    "ax2.axis('off')\n",
    "ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "ax2.set_title('Histogram of Oriented Gradients')\n",
    "ax1.set_adjustable('box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <a id = 'section4'> <font color='grey'>  4. Model Training </font> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters of HOG feature extraction\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "threshold = .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path for positive input dataset\n",
    "pos_im_path = r\"datasets/car1\" \n",
    "\n",
    "# define the path for negative input dataset\n",
    "neg_im_path= r\"datasets/neg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the image files:\n",
    "pos_im_listing = os.listdir(pos_im_path) # it will read all the files in the positive image path (so all the required images)\n",
    "neg_im_listing = os.listdir(neg_im_path)\n",
    "num_pos_samples = size(pos_im_listing) # simply states the total no. of images\n",
    "num_neg_samples = size(neg_im_listing)\n",
    "print(num_pos_samples) # prints the number value of the no.of samples in positive dataset\n",
    "print(num_neg_samples)\n",
    "data= []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute HOG features and label them:\n",
    "\n",
    "#this loop enables reading the files in the pos_im_listing variable one by one\n",
    "for file in pos_im_listing: ne\n",
    "    img = Image.open(pos_im_path + '\\\\' + file) \n",
    "    #img = img.resize((64,128))\n",
    "    gray = img.convert('L') # convert the image into single channel i.e. RGB to grayscale\n",
    "    # calculate HOG for positive features\n",
    "    fd = hog(gray, orientations, pixels_per_cell, cells_per_block, block_norm='L2', feature_vector=True)# fd= feature descriptor\n",
    "    data.append(fd)\n",
    "    labels.append(1)\n",
    "    \n",
    "# Same for the negative images\n",
    "for file in neg_im_listing:\n",
    "    img= Image.open(neg_im_path + '\\\\' + file)\n",
    "    #img = img.resize((64,128))\n",
    "    gray= img.convert('L')\n",
    "    # Calculate the HOG for negative features\n",
    "    fd = hog(gray, orientations, pixels_per_cell, cells_per_block, block_norm='L2', feature_vector=True) \n",
    "    data.append(fd)\n",
    "    labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the labels, converting them from strings to integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partitioning the data into training and testing splits, using 80% of the data for training and the remaining 20% for testing\n",
    "print(\" Constructing training/testing split...\")\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(data), labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Linear SVM Classifier\n",
    "print(\" Training Linear SVM classifier...\")\n",
    "model = LinearSVC()\n",
    "model.fit(trainData, trainLabels)\n",
    "\n",
    "# Evaluating Classifier on test data\n",
    "print(\" Evaluating classifier on test data ...\")\n",
    "predictions = model.predict(testData)\n",
    "print(classification_report(testLabels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model:\n",
    "joblib.dump(model, 'models/model_car.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <a id = 'section5'> <font color='grey'>  5. Testing the Model </font> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define HOG Parameters\n",
    "# change them if necessary to orientations = 8, pixels per cell = (16,16), cells per block to (1,1) for weaker HOG\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2,2)\n",
    "threshold = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sliding window:\n",
    "def sliding_window(image, stepSize, windowSize):# image is the input, step size is the no.of pixels needed to skip and windowSize is the size of the actual window\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0], stepSize):# this line and the line below actually defines the sliding part and loops over the x and y coordinates\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y: y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the saved svm model:\n",
    "model = joblib.load('models/model_car.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained classifier on an image below!\n",
    "scale = 0\n",
    "detections = []\n",
    "# read the image you want to detect the object in:\n",
    "img= cv2.imread(\"test/car1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it with image resized if the image is too big\n",
    "img= cv2.resize(img,(300,200)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the size of the sliding window (has to be, same as the size of the image in the training data)\n",
    "(winW, winH)= (64,128)\n",
    "windowSize=(winW,winH)\n",
    "downscale=1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sliding window:\n",
    "for resized in pyramid_gaussian(img, downscale=1.5): \n",
    "    for (x,y,window) in sliding_window(resized, stepSize=10, windowSize=(winW,winH)):\n",
    "       \n",
    "        if window.shape[0] != winH or window.shape[1] !=winW: \n",
    "            continue\n",
    "        #window=color.rgb2gray(window)\n",
    "        fds = hog(window, orientations, pixels_per_cell, cells_per_block, block_norm='L2')  # extract HOG features from the window captured\n",
    "        fds = fds.reshape(1, -1)\n",
    "        pred = model.predict(fds) # use the SVM model to make a prediction on the HOG features extracted from the window\n",
    "        \n",
    "        if pred == 1:\n",
    "            if model.decision_function(fds) > 0.9: \n",
    "                print(\"Detection:: Location -> ({}, {})\".format(x, y))\n",
    "                print(\"Scale ->  {} | Confidence Score {} \\n\".format(scale,model.decision_function(fds)))\n",
    "                detections.append((int(x * (downscale**scale)), int(y * (downscale**scale)), model.decision_function(fds),\n",
    "                                   int(windowSize[0]*(downscale**scale)), # create a list of all the predictions found\n",
    "                                      int(windowSize[1]*(downscale**scale))))\n",
    "    scale+=1\n",
    "    \n",
    "clone = resized.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this peice of code creates a raw bounding box prior to using NMS\n",
    "for (x_tl, y_tl, _, w, h) in detections:\n",
    "    cv2.rectangle(img, (x_tl, y_tl), (x_tl + w, y_tl + h), (0, 0, 255), thickness = 2)\n",
    "rects = np.array([[x, y, x + w, y + h] for (x, y, _, w, h) in detections]) # do nms on the detected bounding boxes\n",
    "sc = [score[0] for (x, y, score, w, h) in detections]\n",
    "print(\"detection confidence score: \", sc)\n",
    "sc = np.array(sc)\n",
    "pick = non_max_suppression(rects, probs = sc, overlapThresh = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this piece of code creates a bounding box after using nms on the detections\n",
    "for (xA, yA, xB, yB) in pick:\n",
    "    cv2.rectangle(img, (xA, yA), (xB, yB), (0,191,255), 2)\n",
    "    cv2.putText(img,'Person',(xA-2,yA-2),1,0.75,(255,12,34),1)\n",
    "cv2.imshow(\"Raw Detections after NMS\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the images below\n",
    "k= cv2.waitKey(0) & 0xFF \n",
    "if k == 27:             #wait for ESC key to exit\n",
    "    cv2.destroyAllWindows()\n",
    "elif k == ord('s'):\n",
    "    cv2.imwrite('cache/test1.jpg',img)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
